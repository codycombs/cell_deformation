{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test ellipse fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python standard library\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "\n",
    "# Program specific\n",
    "sys.path.append('/home/prestonh/Desktop/Research/pore_stats/pore_stats/rp/')\n",
    "sys.path.append('/home/prestonh/Desktop/Research/pore_stats/pore_stats/oi/')\n",
    "import resistive_pulse as rp\n",
    "import optical_imaging as oi\n",
    "import oi_file\n",
    "\n",
    "\n",
    "# Jupyter\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date = '7-17-2017/'\n",
    "particle = '293-T/'\n",
    "channel = '15-30-15_1/'\n",
    "file_index = '0'\n",
    "\n",
    "base_path = '/home/prestonh/Desktop/Research/cancer_cells/data/'\n",
    "\n",
    "oi_vid_file_path = base_path + date + particle + channel + 'oi/bin/test_camera_' + file_index\n",
    "oi_events_file_path = base_path + date + particle + channel + 'oi/events/test_camera_' + file_index + '_events_filtered.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/prestonh/Desktop/Research/cancer_cells/data/7-17-2017/293-T/15-30-15_1/oi/events/test_camera_0_events_filtered.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fbc62aeabcaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load events\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0moi_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moi_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_event_file_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moi_events_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/prestonh/Desktop/Research/pore_stats/pore_stats/oi/oi_file.pyc\u001b[0m in \u001b[0;36mopen_event_file_json\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0mjson_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'events'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/prestonh/Desktop/Research/cancer_cells/data/7-17-2017/293-T/15-30-15_1/oi/events/test_camera_0_events_filtered.json'"
     ]
    }
   ],
   "source": [
    "# Load video\n",
    "oi_vid = oi_file.Video(oi_vid_file_path, 512, 288, 100000)\n",
    "\n",
    "# Load events\n",
    "oi_events = oi_file.open_event_file_json(oi_events_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "template_index = 0\n",
    "\n",
    "template_frame = oi_vid.get_frame(template_index)\n",
    "\n",
    "plt.imshow(template_frame, cmap = 'gray', origin = 'lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(oi)\n",
    "template_index = 0\n",
    "template_frame = oi_vid.get_frame(template_index)\n",
    "c0 = [115,88]\n",
    "c1 = [115,61]\n",
    "c2 = [360,61]\n",
    "c3 = [360,87]\n",
    "oi_stage = oi.Stage(template_frame, c0, c1, c2, c3)\n",
    "oi_stage.plot_stage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_frame(frame, show = True):\n",
    "    plt.imshow(frame, cmap = 'gray', origin = 'lower', interpolation = 'none')\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "    \n",
    "def plot_processed_over_raw(processed_frame, frame, show = True):\n",
    "    green_processed_frame = np.zeros((processed_frame.shape[0], processed_frame.shape[1], 3))\n",
    "    green_processed_frame[:,:,1] = processed_frame\n",
    "\n",
    "    plt.imshow(frame, cmap = 'gray', origin = 'lower', alpha = 1, interpolation = 'none')\n",
    "    plt.imshow(green_processed_frame, cmap = 'gray', origin = 'lower', alpha = 0.15, interpolation = 'none')\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    \n",
    "def plot_frame_hist(frame, show = True):\n",
    "    plt.hist(frame.flatten(), facecolor = 'k', bins = 100)\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "    \n",
    "def plot_all(processed_frame, frame):\n",
    "    fig, axes = plt.subplots(1,3,figsize = (12,3))\n",
    "    \n",
    "    # Plot 1\n",
    "    plt.sca(axes[0])\n",
    "    plot_frame(processed_frame, show = False)\n",
    "    \n",
    "    \n",
    "    # Plot 2\n",
    "    plt.sca(axes[1])\n",
    "    plot_processed_over_raw(processed_frame, frame, show = False)\n",
    "    \n",
    "    # Plot 3\n",
    "    plt.sca(axes[2])\n",
    "    plot_frame_hist(processed_frame, show = False)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ellipse fitting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_frame(frame, px, py, crop_distance):    \n",
    "    x0 = int(px - crop_distance)\n",
    "    x1 = int(px + crop_distance)\n",
    "    y0 = int(py - crop_distance)\n",
    "    y1 = int(py + crop_distance)\n",
    "    cropped_frame = np.copy(frame)[y0:y1, x0:x1]\n",
    "    \n",
    "    return cropped_frame\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "preprocessing_steps = []\n",
    "def preprocess_frame(frame, template_frame, detection, debug = 'none'):\n",
    "\n",
    "    # Refresh list\n",
    "    del preprocessing_steps[:]\n",
    "\n",
    "    \n",
    "\n",
    "    #################################\n",
    "    # Copy\n",
    "    #################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    preprocessing_steps.append(['copy'])\n",
    "\n",
    "    processed_frame = np.copy(frame)\n",
    "\n",
    "    if debug == 'all':\n",
    "        print 'copy'\n",
    "        plot_all(processed_frame, frame)\n",
    "\n",
    "\n",
    "    #################################\n",
    "    # Negative\n",
    "    #################################\n",
    "\n",
    "\n",
    "\n",
    "    preprocessing_steps.append(['negative'])\n",
    "\n",
    "    processed_frame = np.abs(frame - template_frame)\n",
    "\n",
    "\n",
    "    if debug == 'all':\n",
    "        print 'negative'\n",
    "        plot_all(processed_frame, frame)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #################################\n",
    "    # Blur\n",
    "    #################################\n",
    "\n",
    "\n",
    "    blur_kernel = (3,3)\n",
    "    preprocessing_steps.append(['gaussian blur', blur_kernel])\n",
    "\n",
    "    processed_frame = cv2.GaussianBlur(processed_frame, blur_kernel, 0)\n",
    "\n",
    "\n",
    "\n",
    "    if debug == 'all':\n",
    "        print 'gaussian blur'\n",
    "        plot_all(processed_frame, frame)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #################################\n",
    "    # Rescale\n",
    "    #################################\n",
    "\n",
    "    preprocessing_steps.append(['rescale'])\n",
    "\n",
    "    processed_frame = (processed_frame - np.min(processed_frame))/(np.max(processed_frame) - np.min(processed_frame))\n",
    "\n",
    "\n",
    "\n",
    "    if debug == 'all':\n",
    "        print 'rescale'\n",
    "        plot_all(processed_frame, frame)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #################################\n",
    "    # Threshold\n",
    "    #################################\n",
    "\n",
    "    threshold = .125\n",
    "    preprocessing_steps.append(['pixel intensity threshold', threshold])\n",
    "\n",
    "\n",
    "    processed_frame[processed_frame > threshold] = 1\n",
    "    processed_frame[processed_frame <= threshold] = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if debug == 'all':\n",
    "        print 'threshold'\n",
    "        plot_all(processed_frame, frame)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #################################\n",
    "    # Erode subtraction\n",
    "    #################################\n",
    "    iterations = 1\n",
    "    preprocessing_steps.append(['erode subtraction, iterations = ', iterations])\n",
    "\n",
    "\n",
    "    processed_frame = processed_frame - scipy.ndimage.morphology.binary_erosion(processed_frame, iterations = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if debug == 'all':\n",
    "        print 'erode subtraction'\n",
    "        plot_all(processed_frame, frame)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #################################\n",
    "    # Fill holes\n",
    "    #################################\n",
    "    preprocessing_steps.append(['fill holes'])\n",
    "\n",
    "    processed_frame = scipy.ndimage.binary_fill_holes(processed_frame)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if debug == 'all':\n",
    "        print 'fill holes'\n",
    "        plot_all(processed_frame, frame)\n",
    "\n",
    "    #################################    \n",
    "    # Get largest cluster\n",
    "    #################################\n",
    "\n",
    "    preprocessing_steps.append(['clustering'])\n",
    "\n",
    "\n",
    "    clusters = oi.find_clusters_percentage_based(processed_frame, np.zeros((processed_frame.shape[0], processed_frame.shape[1])), diag = True)\n",
    "    largest_cluster = sorted(clusters, key = lambda x: len(x))[-1]\n",
    "    processed_frame = np.zeros(processed_frame.shape, dtype = np.uint8)\n",
    "    for pixel in largest_cluster:\n",
    "        processed_frame[pixel[0], pixel[1]] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if debug == 'all':\n",
    "        print 'cluster'\n",
    "        plot_all(processed_frame, frame)\n",
    "\n",
    "\n",
    "    #################################\n",
    "    # Morphological closing\n",
    "    #################################\n",
    "\n",
    "    morph_kernel_size = (10,10)\n",
    "    preprocessing_steps.append(['morphological closing, kernel = ', morph_kernel_size])\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, morph_kernel_size)\n",
    "    processed_frame = cv2.morphologyEx(np.array(processed_frame, dtype = np.uint8), cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "\n",
    "    if debug == 'all':\n",
    "        print 'morphological closing'\n",
    "        plot_all(processed_frame, frame)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #################################\n",
    "    # Erode subtraction\n",
    "    #################################\n",
    "\n",
    "    iterations = 3\n",
    "    preprocessing_steps.append(['erosion subtraction, iterations = ', iterations])\n",
    "\n",
    "\n",
    "\n",
    "    processed_frame = processed_frame - scipy.ndimage.morphology.binary_erosion(processed_frame, iterations = iterations)\n",
    "\n",
    "\n",
    "    if debug == 'all':\n",
    "        print 'erode subtraction'\n",
    "        plot_all(processed_frame, frame)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    if debug == 'last':\n",
    "        plot_all(processed_frame, frame)\n",
    "        \n",
    "        \n",
    "    return processed_frame\n",
    "\n",
    "\n",
    "\n",
    "def fit_ellipse(processed_frame, debug = False):\n",
    "\n",
    "    #################################\n",
    "    # Fit ellipse\n",
    "    #################################\n",
    "\n",
    "\n",
    "\n",
    "    cell_pixels = np.where(processed_frame == 1)\n",
    "\n",
    "    ellipse = oi.fit_ellipse(cell_pixels[0], cell_pixels[1])\n",
    "    \n",
    "    \n",
    "    if debug:\n",
    "        ellipse_center = oi.get_ellipse_center(ellipse)\n",
    "        ellipse_angle = oi.get_ellipse_angle(ellipse)\n",
    "        ellipse_axes = oi.get_ellipse_axes_lengths(ellipse)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ellipse_points = np.empty((100,2))\n",
    "        for i in range(100):\n",
    "            angle = i*2*np.pi/99.\n",
    "            x = ellipse_axes[0]*np.cos(angle)\n",
    "            y = ellipse_axes[1]*np.sin(angle)\n",
    "            ellipse_points[i,1] = ellipse_center[0] + np.cos(ellipse_angle)*x - np.sin(ellipse_angle)*y\n",
    "            ellipse_points[i,0] = ellipse_center[1] + np.sin(ellipse_angle)*x + np.cos(ellipse_angle)*y\n",
    "\n",
    "\n",
    "        green_processed_frame = np.zeros((processed_frame.shape[0], processed_frame.shape[1], 3))\n",
    "        green_processed_frame[:,:,1] = processed_frame\n",
    "\n",
    "\n",
    "\n",
    "        plt.imshow(frame, cmap = 'gray', origin = 'lower', interpolation = 'none')\n",
    "        plt.imshow(green_processed_frame, alpha = .15, origin = 'lower', interpolation = 'none')\n",
    "        plt.plot(ellipse_points[:,0], ellipse_points[:,1], lw = 0.5, c = 'yellow')\n",
    "\n",
    "        plt.xlim(0, frame.shape[1])\n",
    "        plt.ylim(0, frame.shape[0])\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    return ellipse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find event to test fit on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oi_index = 16\n",
    "oi_event = oi_events[oi_index]\n",
    "reload(oi_file)\n",
    "plt.close()\n",
    "HTML(oi_file.make_animation(oi_vid, oi_event._detections[0]._tf, oi_event._detections[-1]._tf).to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oi_event = oi_\n",
    "for j, detection in enumerate(oi_event._detections):\n",
    "        \n",
    "    try:\n",
    "\n",
    "        # Get raw frame\n",
    "        raw_frame = oi_vid.get_frame(detection._tf)\n",
    "\n",
    "\n",
    "        # Crop frames\n",
    "        cropped_frame = crop_frame(raw_frame, detection._px, detection._py, 30)\n",
    "        cropped_template_frame = crop_frame(template_frame, detection._px, detection._py, 30)\n",
    "\n",
    "\n",
    "        # Preprocess frame\n",
    "        processed_frame = preprocess_frame(cropped_frame, cropped_template_frame, detection, debug = 'last')\n",
    "\n",
    "\n",
    "        # Get ellipse + parameters\n",
    "        ellipse = fit_ellipse(processed_frame)\n",
    "        ellipse_axes = oi.get_ellipse_axes_lengths(ellipse)\n",
    "        ellipse_center = oi.get_ellipse_center(ellipse)\n",
    "        ellipse_center[0] = ellipse_center[0] + (detection._px - 30)\n",
    "        ellipse_center[1] = ellipse_center[1] + (detection._py - 30)\n",
    "\n",
    "        ellipse_angle = oi.get_ellipse_angle(ellipse)\n",
    "\n",
    "        ellipsess[-1].append([j, ellipse_center[0], ellipse_center[1], ellipse_axes[0], ellipse_axes[1], ellipse_angle])\n",
    "\n",
    "\n",
    "    except:\n",
    "\n",
    "        print '\\tfailed on', j, '/', len(oi_event._detections)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
